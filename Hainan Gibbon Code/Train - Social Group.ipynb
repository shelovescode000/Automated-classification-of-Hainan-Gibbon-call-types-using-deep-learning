{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "**Paper:** Bioacoustic classification of Hainan Gibbon call types using Deep Learning\n",
    "\n",
    "**Code Date:** April 2022\n",
    "\n",
    "**Repository:** https://github.com/shelovescode000/Automated-classification-of-Hainan-Gibbon-call-types-using-deep-learning\n",
    "\n",
    "**Notebook description:** Train a CNN on the augmented spectrogram images.\n",
    "\n",
    "<hr>\n",
    "\n",
    "**Note 1: Code was adapted from https://github.com/emmanueldufourq/GibbonClassifier.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colab = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if colab:\n",
    "    !pip install SoundFile\n",
    "    from google.colab import drive\n",
    "    from pydrive.auth import GoogleAuth\n",
    "    from pydrive.drive import GoogleDrive\n",
    "    from google.colab import auth\n",
    "    from oauth2client.client import GoogleCredentials\n",
    "    import tarfile\n",
    "\n",
    "    # Google Authentication\n",
    "    auth.authenticate_user()\n",
    "    gauth = GoogleAuth()\n",
    "    gauth.credentials = GoogleCredentials.get_application_default()\n",
    "    drive = GoogleDrive(gauth)\n",
    "\n",
    "    # Download data files\n",
    "    downloaded = drive.CreateFile({'id':\"1u7orJHwGOMIcyqwiiEl2e7KEZpnT_0h7\"})\n",
    "    downloaded.GetContentFile('GibbonClassifierData.tar.gz')\n",
    "\n",
    "    # Extract files to temporary location in Google Drive\n",
    "    with tarfile.open('GibbonClassifierData.tar.gz', 'r:gz') as tar:\n",
    "        tar.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from Train_Helper3 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_directory = 'Raw_Data/Train/'\n",
    "timestamp_directory = 'Call_Labels/'\n",
    "save_location = 'Pickled_Data/'\n",
    "augment_directory = 'Augmented_Data/'\n",
    "augment_image_directory = 'Augmented_Image_Data/'\n",
    "training_file = 'Training_Files.txt'\n",
    "\n",
    "audio_directory_validation = 'Raw_Data/Validation/'\n",
    "timestamp_directory_validation = 'Call_Labels_Validation/'\n",
    "save_location_validation = 'Pickled_Data_Validation/'\n",
    "augment_directory_validation = 'Augmented_Data_Validation/'\n",
    "augment_image_directory_validation = 'Augmented_Image_Data_Validation/'\n",
    "validation_file = 'Validation_Files.txt'\n",
    "\n",
    "audio_directory_testing = 'Raw_Data/Test/'\n",
    "timestamp_directory_testing = 'Call_Labels_Testing/'\n",
    "save_location_testing = 'Pickled_Data_Testing/'\n",
    "augment_directory_testing = 'Images_Testing/'\n",
    "augment_image_directory_testing = 'Images_Testing2/'\n",
    "testing_file = 'Testing_Files.txt'\n",
    "\n",
    "sample_rate = 4800\n",
    "number_seconds_to_extract = 10\n",
    "seed = 42\n",
    "number_iterations = 1\n",
    "augmentation_probability = 1.0\n",
    "augmentation_amount_noise = 2\n",
    "augmentation_amount_gibbon = 10\n",
    "\n",
    "sample_rate = 4800\n",
    "number_seconds_to_extract = 10\n",
    "seed = 42\n",
    "number_iterations = 1\n",
    "augmentation_probability = 1.0\n",
    "augmentation_amount_noise = 2\n",
    "augmentation_amount_gibbon = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract segments, preprocessing and augment all training files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execute_preprocessing_all_files(training_file, audio_directory, \n",
    "                            sample_rate, timestamp_directory,\n",
    "                            number_seconds_to_extract, save_location,\n",
    "                            augmentation_amount_noise, augmentation_probability, \n",
    "                            augmentation_amount_gibbon, seed, augment_directory, augment_image_directory,\n",
    "                            number_iterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Begin training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "\n",
      "----------------------------------\n",
      "Reading file: HGSM3C_0+1_20150807_052200.wav\n",
      "Reading file gibbon augmented file:  HGSM3C_0+1_20150807_052200\n",
      "Reading non-gibbon augmented file: HGSM3C_0+1_20150807_052200\n",
      "\n",
      "----------------------------------\n",
      "Reading file: HGSM3C_0+1_20150811_052300.wav\n",
      "Reading file gibbon augmented file:  HGSM3C_0+1_20150811_052300\n",
      "Reading non-gibbon augmented file: HGSM3C_0+1_20150811_052300\n",
      "\n",
      "----------------------------------\n",
      "Reading file: HGSM3C_0+1_20160501_051500.wav\n",
      "Reading file gibbon augmented file:  HGSM3C_0+1_20160501_051500\n",
      "Reading non-gibbon augmented file: HGSM3C_0+1_20160501_051500\n",
      "\n",
      "----------------------------------\n",
      "Reading file: HGSM3C_0+1_20160517_050800.wav\n",
      "Reading file gibbon augmented file:  HGSM3C_0+1_20160517_050800\n",
      "Reading non-gibbon augmented file: HGSM3C_0+1_20160517_050800\n",
      "\n",
      "----------------------------------\n",
      "Reading file: HGSM3C_0+1_20160518_050700.wav\n",
      "Reading file gibbon augmented file:  HGSM3C_0+1_20160518_050700\n",
      "Reading non-gibbon augmented file: HGSM3C_0+1_20160518_050700\n",
      "\n",
      "----------------------------------\n",
      "Reading file: HGSM3C_0+1_20160519_050700.wav\n",
      "Reading file gibbon augmented file:  HGSM3C_0+1_20160519_050700\n",
      "Reading non-gibbon augmented file: HGSM3C_0+1_20160519_050700\n",
      "\n",
      "----------------------------------\n",
      "Reading file: HGSM3C_0+1_20150804_052100.wav\n",
      "Reading file gibbon augmented file:  HGSM3C_0+1_20150804_052100\n",
      "Reading non-gibbon augmented file: HGSM3C_0+1_20150804_052100\n",
      "\n",
      "----------------------------------\n",
      "Reading file: HGSM3C_0+1_20150805_052100.wav\n",
      "Reading file gibbon augmented file:  HGSM3C_0+1_20150805_052100\n",
      "Reading non-gibbon augmented file: HGSM3C_0+1_20150805_052100\n",
      "\n",
      "----------------------------------\n",
      "Reading file: HGSM3C_0+1_20150810_052200.wav\n",
      "Reading file gibbon augmented file:  HGSM3C_0+1_20150810_052200\n",
      "Reading non-gibbon augmented file: HGSM3C_0+1_20150810_052200\n",
      "\n",
      "----------------------------------\n",
      "Reading file: HGSM3C_0+1_20160520_050700.wav\n",
      "Reading file gibbon augmented file:  HGSM3C_0+1_20160520_050700\n",
      "Reading non-gibbon augmented file: HGSM3C_0+1_20160520_050700\n",
      "\n",
      "----------------------------------\n",
      "Reading file: HGSM3C_0+1_20150812_052300.wav\n",
      "Reading file gibbon augmented file:  HGSM3C_0+1_20150812_052300\n",
      "Reading non-gibbon augmented file: HGSM3C_0+1_20150812_052300\n",
      "\n",
      "----------------------------------\n",
      "Reading file: HGSM3A_0+1_20150715_051400.wav\n",
      "Reading file gibbon augmented file:  HGSM3A_0+1_20150715_051400\n",
      "Reading non-gibbon augmented file: HGSM3A_0+1_20150715_051400\n",
      "\n",
      "----------------------------------\n",
      "Reading file: HGSM3A_0+1_20160304_060000.wav\n",
      "Reading file gibbon augmented file:  HGSM3A_0+1_20160304_060000\n",
      "Reading non-gibbon augmented file: HGSM3A_0+1_20160304_060000\n",
      "\n",
      "----------------------------------\n",
      "Reading file: HGSM3A_0+1_20160309_055600.wav\n",
      "Reading file gibbon augmented file:  HGSM3A_0+1_20160309_055600\n",
      "Reading non-gibbon augmented file: HGSM3A_0+1_20160309_055600\n",
      "\n",
      "----------------------------------\n",
      "Reading file: HGSM3A_0+1_20160311_055500.wav\n",
      "Reading file gibbon augmented file:  HGSM3A_0+1_20160311_055500\n",
      "Reading non-gibbon augmented file: HGSM3A_0+1_20160311_055500\n",
      "\n",
      "----------------------------------\n",
      "Reading file: HGSM3A_0+1_20160328_054100.wav\n",
      "Reading file gibbon augmented file:  HGSM3A_0+1_20160328_054100\n",
      "Reading non-gibbon augmented file: HGSM3A_0+1_20160328_054100\n",
      "\n",
      "----------------------------------\n",
      "Reading file: HGSM3A_0+1_20160329_054000.wav\n",
      "Reading file gibbon augmented file:  HGSM3A_0+1_20160329_054000\n",
      "Reading non-gibbon augmented file: HGSM3A_0+1_20160329_054000\n",
      "\n",
      "----------------------------------\n",
      "Reading file: HGSM3A_0+1_20160330_053900.wav\n",
      "Reading file gibbon augmented file:  HGSM3A_0+1_20160330_053900\n",
      "Reading non-gibbon augmented file: HGSM3A_0+1_20160330_053900\n",
      "\n",
      "----------------------------------\n",
      "Reading file: HGSM3AB_0+1_20160316_055100.wav\n",
      "Reading file gibbon augmented file:  HGSM3AB_0+1_20160316_055100\n",
      "Reading file gibbon augmented file:  HGSM3AB_0+1_20160316_055100\n",
      "Reading non-gibbon augmented file: HGSM3AB_0+1_20160316_055100\n",
      "\n",
      "----------------------------------\n",
      "Reading file: HGSM3B_0+1_20150617_050600.wav\n",
      "Reading file gibbon augmented file:  HGSM3B_0+1_20150617_050600\n",
      "Reading non-gibbon augmented file: HGSM3B_0+1_20150617_050600\n",
      "\n",
      "----------------------------------\n",
      "Reading file: HGSM3B_0+1_20160305_060000.wav\n",
      "Reading file gibbon augmented file:  HGSM3B_0+1_20160305_060000\n",
      "Reading non-gibbon augmented file: HGSM3B_0+1_20160305_060000\n",
      "\n",
      "----------------------------------\n",
      "Reading file: HGSM3D_0+1_20160404_053500.wav\n",
      "Reading file gibbon augmented file:  HGSM3D_0+1_20160404_053500\n",
      "Reading non-gibbon augmented file: HGSM3D_0+1_20160404_053500\n",
      "\n",
      "----------------------------------\n",
      "Reading file: HGSM3D_0+1_20160603_050500.wav\n",
      "Reading file gibbon augmented file:  HGSM3D_0+1_20160603_050500\n",
      "Reading non-gibbon augmented file: HGSM3D_0+1_20160603_050500\n",
      "\n",
      "----------------------------------\n",
      "Reading file: HGSM3D_0+1_20160605_050500.wav\n",
      "Reading file gibbon augmented file:  HGSM3D_0+1_20160605_050500\n",
      "Reading non-gibbon augmented file: HGSM3D_0+1_20160605_050500\n",
      "\n",
      "----------------------------------\n",
      "Reading file: HGSM3D_0+1_20160608_050500.wav\n",
      "Reading file gibbon augmented file:  HGSM3D_0+1_20160608_050500\n",
      "Reading non-gibbon augmented file: HGSM3D_0+1_20160608_050500\n",
      "\n",
      "----------------------------------\n",
      "Reading file: HGSM3C_0+1_20150806_052100.wav\n",
      "Reading file gibbon augmented file:  HGSM3C_0+1_20150806_052100\n",
      "Reading non-gibbon augmented file: HGSM3C_0+1_20150806_052100\n",
      "\n",
      "B Gibbon features: (9950, 128, 188, 1)\n",
      "C Gibbon features: (7490, 128, 188, 1)\n",
      "D Gibbon features: (8210, 128, 188, 1)\n",
      "Non-gibbon features (22620, 128, 188, 1)\n",
      "\n",
      "----------------------------------\n",
      "Reading file: HGSM3B_0+1_20150616_050500.wav\n",
      "Reading file gibbon augmented file:  HGSM3B_0+1_20150616_050500\n",
      "Reading non-gibbon augmented file: HGSM3B_0+1_20150616_050500\n",
      "\n",
      "----------------------------------\n",
      "Reading file: HGSM3AB_0+1_20160318_054900.wav\n",
      "Reading file gibbon augmented file:  HGSM3AB_0+1_20160318_054900\n",
      "Reading file gibbon augmented file:  HGSM3AB_0+1_20160318_054900\n",
      "Reading non-gibbon augmented file: HGSM3AB_0+1_20160318_054900\n",
      "\n",
      "----------------------------------\n",
      "Reading file: HGSM3B_0+1_20160316_055100.wav\n",
      "Reading file gibbon augmented file:  HGSM3B_0+1_20160316_055100\n",
      "Reading non-gibbon augmented file: HGSM3B_0+1_20160316_055100\n",
      "\n",
      "----------------------------------\n",
      "Reading file: HGSM3B_0+1_20160330_053900.wav\n",
      "Reading file gibbon augmented file:  HGSM3B_0+1_20160330_053900\n",
      "Reading non-gibbon augmented file: HGSM3B_0+1_20160330_053900\n",
      "\n",
      "----------------------------------\n",
      "Reading file: HGSM3D_0+1_20160402_053600.wav\n",
      "Reading file gibbon augmented file:  HGSM3D_0+1_20160402_053600\n",
      "Reading non-gibbon augmented file: HGSM3D_0+1_20160402_053600\n",
      "\n",
      "----------------------------------\n",
      "Reading file: HGSM3D_0+1_20160403_053600.wav\n",
      "Reading file gibbon augmented file:  HGSM3D_0+1_20160403_053600\n",
      "Reading non-gibbon augmented file: HGSM3D_0+1_20160403_053600\n",
      "\n",
      "----------------------------------\n",
      "Reading file: HGSM3D_0+1_20160606_050500.wav\n",
      "Reading file gibbon augmented file:  HGSM3D_0+1_20160606_050500\n",
      "Reading non-gibbon augmented file: HGSM3D_0+1_20160606_050500\n",
      "\n",
      "----------------------------------\n",
      "Reading file: HGSM3D_0+1_20160607_050500.wav\n",
      "Reading file gibbon augmented file:  HGSM3D_0+1_20160607_050500\n",
      "Reading non-gibbon augmented file: HGSM3D_0+1_20160607_050500\n",
      "\n",
      "----------------------------------\n",
      "Reading file: HGSM3C_0+1_20160314_055200.wav\n",
      "Reading file gibbon augmented file:  HGSM3C_0+1_20160314_055200\n",
      "Reading non-gibbon augmented file: HGSM3C_0+1_20160314_055200\n",
      "\n",
      "----------------------------------\n",
      "Reading file: HGSM3C_0+1_20150809_052200.wav\n",
      "Reading file gibbon augmented file:  HGSM3C_0+1_20150809_052200\n",
      "Reading non-gibbon augmented file: HGSM3C_0+1_20150809_052200\n",
      "\n",
      "B Gibbon features: (2780, 128, 188, 1)\n",
      "C Gibbon features: (2370, 128, 188, 1)\n",
      "D Gibbon features: (2480, 128, 188, 1)\n",
      "Non-gibbon features (7540, 128, 188, 1)\n",
      "\n",
      "Data loaded.\n",
      "Processing...\n",
      "Processing done.\n",
      "\n",
      "Shape of X (48270, 128, 188, 1)\n",
      "Shape of Y (48270, 4)\n",
      "Shape of X (15170, 128, 188, 1)\n",
      "Shape of Y (15170, 4)\n"
     ]
    }
   ],
   "source": [
    "    print('Loading data...')\n",
    "    training_files = []\n",
    "    validation_files = []\n",
    "    gibbon_XB,gibbon_XC,gibbon_XD,non_gibbon_X = load_training_images(augment_image_directory, training_file)\n",
    "    gibbon_XB_v,gibbon_XC_v,gibbon_XD_v,non_gibbon_X_v = load_training_images(augment_image_directory_validation, validation_file)\n",
    "    \n",
    "    print()\n",
    "    print ('Data loaded.')\n",
    "    print ('Processing...')\n",
    "    X_train, Y_train = prepare_X_and_Y(gibbon_XB,gibbon_XC,gibbon_XD, non_gibbon_X)\n",
    "    del gibbon_XB,gibbon_XC, gibbon_XD, non_gibbon_X\n",
    "    X_val, Y_val = prepare_X_and_Y(gibbon_XB_v,gibbon_XC_v,gibbon_XD_v, non_gibbon_X_v)\n",
    "    del gibbon_XB_v,gibbon_XC_v, gibbon_XD_v, non_gibbon_X_v    \n",
    "    print ('Processing done.')\n",
    "    print()\n",
    "    print ('Shape of X', X_train.shape)\n",
    "    print ('Shape of Y', Y_train.shape) #3310 #796  #38\n",
    "    print ('Shape of X', X_val.shape)\n",
    "    print ('Shape of Y', Y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 starting...\n",
      "experiment_id: 0\n",
      "X_train: (48270, 128, 188, 1)\n",
      "Y_train: (48270, 4)\n",
      "\n",
      "X_val: (15170, 128, 188, 1)\n",
      "Y_val: (15170, 4)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 113, 173, 8)       2056      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 113, 173, 8)       0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 28, 43, 8)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 13, 28, 8)         16392     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 13, 28, 8)         0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 3, 7, 8)          0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 168)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                5408      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4)                 132       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,988\n",
      "Trainable params: 23,988\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.66592, saving model to Experiments\\weights_2022.hdf5\n",
      "1509/1509 - 1367s - loss: 0.7383 - accuracy: 0.6944 - val_loss: 1.0666 - val_accuracy: 0.6659 - 1367s/epoch - 906ms/step\n",
      "Epoch 2/10\n",
      "\n",
      "Epoch 2: val_accuracy improved from 0.66592 to 0.70831, saving model to Experiments\\weights_2022.hdf5\n",
      "1509/1509 - 1337s - loss: 0.4173 - accuracy: 0.8185 - val_loss: 0.9334 - val_accuracy: 0.7083 - 1337s/epoch - 886ms/step\n",
      "Epoch 3/10\n",
      "\n",
      "Epoch 3: val_accuracy improved from 0.70831 to 0.73448, saving model to Experiments\\weights_2022.hdf5\n",
      "1509/1509 - 1343s - loss: 0.3254 - accuracy: 0.8525 - val_loss: 0.9834 - val_accuracy: 0.7345 - 1343s/epoch - 890ms/step\n",
      "Epoch 4/10\n",
      "\n",
      "Epoch 4: val_accuracy improved from 0.73448 to 0.73889, saving model to Experiments\\weights_2022.hdf5\n",
      "1509/1509 - 1341s - loss: 0.2701 - accuracy: 0.8734 - val_loss: 1.2559 - val_accuracy: 0.7389 - 1341s/epoch - 889ms/step\n",
      "Epoch 5/10\n",
      "\n",
      "Epoch 5: val_accuracy did not improve from 0.73889\n",
      "1509/1509 - 1039s - loss: 0.2455 - accuracy: 0.8839 - val_loss: 1.0853 - val_accuracy: 0.7245 - 1039s/epoch - 689ms/step\n",
      "Epoch 6/10\n",
      "\n",
      "Epoch 6: val_accuracy did not improve from 0.73889\n",
      "1509/1509 - 688s - loss: 0.2331 - accuracy: 0.8868 - val_loss: 1.3676 - val_accuracy: 0.7206 - 688s/epoch - 456ms/step\n",
      "Epoch 7/10\n",
      "\n",
      "Epoch 7: val_accuracy did not improve from 0.73889\n",
      "1509/1509 - 694s - loss: 0.2131 - accuracy: 0.8951 - val_loss: 1.4128 - val_accuracy: 0.7198 - 694s/epoch - 460ms/step\n",
      "Epoch 8/10\n",
      "\n",
      "Epoch 8: val_accuracy did not improve from 0.73889\n",
      "1509/1509 - 696s - loss: 0.1976 - accuracy: 0.9006 - val_loss: 1.4172 - val_accuracy: 0.7343 - 696s/epoch - 461ms/step\n",
      "Epoch 9/10\n",
      "\n",
      "Epoch 9: val_accuracy improved from 0.73889 to 0.74417, saving model to Experiments\\weights_2022.hdf5\n",
      "1509/1509 - 698s - loss: 0.2111 - accuracy: 0.8992 - val_loss: 1.8012 - val_accuracy: 0.7442 - 698s/epoch - 462ms/step\n",
      "Epoch 10/10\n",
      "\n",
      "Epoch 10: val_accuracy did not improve from 0.74417\n",
      "1509/1509 - 691s - loss: 0.1813 - accuracy: 0.9056 - val_loss: 1.6726 - val_accuracy: 0.7428 - 691s/epoch - 458ms/step\n",
      "training accuracy =  0.8816449140252745\n",
      "validation accuracy =  0.744166117336849\n"
     ]
    }
   ],
   "source": [
    "seed = 2022\n",
    "        \n",
    "for experiment_id in range(0,number_iterations):\n",
    "\n",
    "        print('Iteration {} starting...'.format(experiment_id))\n",
    "\n",
    "        print ('experiment_id: {}'.format(experiment_id))\n",
    "\n",
    "        \n",
    "        #X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.20, \n",
    "        #                                                    random_state=seed, shuffle = True)\n",
    "        X_train, Y_train = shuffle(X_train,Y_train)\n",
    "        X_val, Y_val = shuffle(X_val,Y_val)\n",
    "        \n",
    "        # Check shape\n",
    "        print ('X_train:',X_train.shape)\n",
    "        print ('Y_train:',Y_train.shape)\n",
    "        print ()\n",
    "        print ('X_val:',X_val.shape)\n",
    "        print ('Y_val:',Y_val.shape)\n",
    "\n",
    "        # Call backs to save weights\n",
    "        filepath= \"Experiments/weights_{}.hdf5\".format(seed)\n",
    "        checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy',verbose=1, save_best_only=True, mode='max')\n",
    "        #callbacks_list = [checkpoint]\n",
    "        \n",
    "        model = network()\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "        \n",
    "        model.summary()\n",
    "        \n",
    "        start = time.time()\n",
    "\n",
    "        history = model.fit(X_train, Y_train, validation_data=(X_val, Y_val), \n",
    "                  batch_size=32,\n",
    "                  epochs=10,\n",
    "                  verbose=2, \n",
    "                  callbacks=[checkpoint]) \n",
    "                  #class_weight={0:1.,1:1.}\n",
    "        end = time.time()\n",
    "        \n",
    "        model.load_weights(\"Experiments/weights_{}.hdf5\".format(seed))\n",
    "        train_acc = accuracy_score(np.argmax(model.predict(X_train),1),np.argmax(Y_train,1))\n",
    "        print(\"training accuracy = \",train_acc)\n",
    "\n",
    "        val_acc = accuracy_score(np.argmax(model.predict(X_val),1), np.argmax(Y_val,1))\n",
    "        print(\"validation accuracy = \",val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 starting...\n",
      "experiment_id: 0\n",
      "X_train: (48270, 128, 188, 1)\n",
      "Y_train: (48270, 4)\n",
      "\n",
      "X_val: (15170, 128, 188, 1)\n",
      "Y_val: (15170, 4)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 113, 173, 8)       2056      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 113, 173, 8)       0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 28, 43, 8)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 13, 28, 8)         16392     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 13, 28, 8)         0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 3, 7, 8)          0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 168)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                5408      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4)                 132       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,988\n",
      "Trainable params: 23,988\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/7\n",
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.62874, saving model to Experiments\\weights_2022.hdf5\n",
      "3017/3017 - 1426s - loss: 0.6597 - accuracy: 0.7187 - val_loss: 1.4830 - val_accuracy: 0.6287 - 1426s/epoch - 473ms/step\n",
      "Epoch 2/7\n",
      "\n",
      "Epoch 2: val_accuracy improved from 0.62874 to 0.66533, saving model to Experiments\\weights_2022.hdf5\n",
      "3017/3017 - 1406s - loss: 0.3693 - accuracy: 0.8363 - val_loss: 1.9280 - val_accuracy: 0.6653 - 1406s/epoch - 466ms/step\n",
      "Epoch 3/7\n",
      "\n",
      "Epoch 3: val_accuracy improved from 0.66533 to 0.66790, saving model to Experiments\\weights_2022.hdf5\n",
      "3017/3017 - 2959s - loss: 0.2881 - accuracy: 0.8645 - val_loss: 2.4723 - val_accuracy: 0.6679 - 2959s/epoch - 981ms/step\n",
      "Epoch 4/7\n",
      "\n",
      "Epoch 4: val_accuracy improved from 0.66790 to 0.67436, saving model to Experiments\\weights_2022.hdf5\n",
      "3017/3017 - 1405s - loss: 0.2428 - accuracy: 0.8819 - val_loss: 3.3247 - val_accuracy: 0.6744 - 1405s/epoch - 466ms/step\n",
      "Epoch 5/7\n",
      "\n",
      "Epoch 5: val_accuracy did not improve from 0.67436\n",
      "3017/3017 - 1408s - loss: 0.2203 - accuracy: 0.8892 - val_loss: 3.1587 - val_accuracy: 0.6667 - 1408s/epoch - 467ms/step\n",
      "Epoch 6/7\n",
      "\n",
      "Epoch 6: val_accuracy improved from 0.67436 to 0.69400, saving model to Experiments\\weights_2022.hdf5\n",
      "3017/3017 - 1399s - loss: 0.2013 - accuracy: 0.8981 - val_loss: 4.0006 - val_accuracy: 0.6940 - 1399s/epoch - 464ms/step\n",
      "Epoch 7/7\n",
      "\n",
      "Epoch 7: val_accuracy did not improve from 0.69400\n",
      "3017/3017 - 872s - loss: 0.1897 - accuracy: 0.9029 - val_loss: 4.8015 - val_accuracy: 0.6898 - 872s/epoch - 289ms/step\n",
      "training accuracy =  0.9192044748290864\n",
      "validation accuracy =  0.6940013183915623\n"
     ]
    }
   ],
   "source": [
    "seed = 2022\n",
    "        \n",
    "for experiment_id in range(0,number_iterations):\n",
    "\n",
    "        print('Iteration {} starting...'.format(experiment_id))\n",
    "\n",
    "        print ('experiment_id: {}'.format(experiment_id))\n",
    "\n",
    "        \n",
    "        #X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.20, \n",
    "        #                                                    random_state=seed, shuffle = True)\n",
    "        #X_train, Y_train = shuffle(X_train,Y_train)\n",
    "        #X_val, Y_val = shuffle(X_val,Y_val)\n",
    "        \n",
    "        # Check shape\n",
    "        print ('X_train:',X_train.shape)\n",
    "        print ('Y_train:',Y_train.shape)\n",
    "        print ()\n",
    "        print ('X_val:',X_val.shape)\n",
    "        print ('Y_val:',Y_val.shape)\n",
    "\n",
    "        # Call backs to save weights\n",
    "        filepath= \"Experiments/weights_MODEL1_{}.hdf5\".format(seed)\n",
    "        checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy',verbose=1, save_best_only=True, mode='max')\n",
    "        #callbacks_list = [checkpoint]\n",
    "        \n",
    "        model1 = network1()\n",
    "        model1.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "        \n",
    "        model1.summary()\n",
    "        \n",
    "        start = time.time()\n",
    "\n",
    "        history1 = model1.fit(X_train, Y_train, validation_data=(X_val, Y_val), \n",
    "                  batch_size=16,\n",
    "                  epochs=7,\n",
    "                  verbose=2, \n",
    "                  callbacks=[checkpoint]) \n",
    "                  #class_weight={0:1.,1:1.}\n",
    "        end = time.time()\n",
    "        \n",
    "        model1.load_weights(\"Experiments/weights_MODEL1_{}.hdf5\".format(seed))\n",
    "        train_acc1 = accuracy_score(np.argmax(model1.predict(X_train),1),np.argmax(Y_train,1))\n",
    "        print(\"training accuracy = \",train_acc1)\n",
    "\n",
    "        val_acc1 = accuracy_score(np.argmax(model1.predict(X_val),1), np.argmax(Y_val,1))\n",
    "        print(\"validation accuracy = \",val_acc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 starting...\n",
      "experiment_id: 0\n",
      "X_train: (48270, 128, 188, 1)\n",
      "Y_train: (48270, 4)\n",
      "\n",
      "X_val: (15170, 128, 188, 1)\n",
      "Y_val: (15170, 4)\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2 (Conv2D)           (None, 113, 173, 8)       2056      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 113, 173, 8)       0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 28, 43, 8)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 13, 28, 8)         16392     \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 13, 28, 8)         0         \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 3, 7, 8)          0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 168)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                5408      \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 4)                 132       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,988\n",
      "Trainable params: 23,988\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/7\n",
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.67291, saving model to Experiments\\weights_MODEL2_2022.hdf5\n",
      "1509/1509 - 2929s - loss: 0.7219 - accuracy: 0.6908 - val_loss: 1.1718 - val_accuracy: 0.6729 - 2929s/epoch - 2s/step\n",
      "Epoch 2/7\n",
      "\n",
      "Epoch 2: val_accuracy improved from 0.67291 to 0.69908, saving model to Experiments\\weights_MODEL2_2022.hdf5\n",
      "1509/1509 - 1342s - loss: 0.4369 - accuracy: 0.8088 - val_loss: 1.2833 - val_accuracy: 0.6991 - 1342s/epoch - 889ms/step\n",
      "Epoch 3/7\n",
      "\n",
      "Epoch 3: val_accuracy improved from 0.69908 to 0.70369, saving model to Experiments\\weights_MODEL2_2022.hdf5\n",
      "1509/1509 - 1342s - loss: 0.3396 - accuracy: 0.8462 - val_loss: 1.1147 - val_accuracy: 0.7037 - 1342s/epoch - 890ms/step\n",
      "Epoch 4/7\n",
      "\n",
      "Epoch 4: val_accuracy did not improve from 0.70369\n",
      "1509/1509 - 1337s - loss: 0.2787 - accuracy: 0.8681 - val_loss: 1.4261 - val_accuracy: 0.6775 - 1337s/epoch - 886ms/step\n",
      "Epoch 5/7\n",
      "\n",
      "Epoch 5: val_accuracy improved from 0.70369 to 0.71503, saving model to Experiments\\weights_MODEL2_2022.hdf5\n",
      "1509/1509 - 1344s - loss: 0.2514 - accuracy: 0.8793 - val_loss: 1.4415 - val_accuracy: 0.7150 - 1344s/epoch - 891ms/step\n",
      "Epoch 6/7\n",
      "\n",
      "Epoch 6: val_accuracy improved from 0.71503 to 0.73764, saving model to Experiments\\weights_MODEL2_2022.hdf5\n",
      "1509/1509 - 1346s - loss: 0.2292 - accuracy: 0.8898 - val_loss: 1.9286 - val_accuracy: 0.7376 - 1346s/epoch - 892ms/step\n",
      "Epoch 7/7\n",
      "\n",
      "Epoch 7: val_accuracy did not improve from 0.73764\n",
      "1509/1509 - 1339s - loss: 0.2063 - accuracy: 0.8978 - val_loss: 1.6881 - val_accuracy: 0.6512 - 1339s/epoch - 887ms/step\n",
      "training accuracy =  0.9049720323182101\n",
      "validation accuracy =  0.7376400791034937\n"
     ]
    }
   ],
   "source": [
    "seed = 2022\n",
    "        \n",
    "for experiment_id in range(0,number_iterations):\n",
    "\n",
    "        print('Iteration {} starting...'.format(experiment_id))\n",
    "\n",
    "        print ('experiment_id: {}'.format(experiment_id))\n",
    "\n",
    "        \n",
    "        #X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.20, \n",
    "        #                                                    random_state=seed, shuffle = True)\n",
    "        #X_train, Y_train = shuffle(X_train,Y_train)\n",
    "        #X_val, Y_val = shuffle(X_val,Y_val)\n",
    "        \n",
    "        # Check shape\n",
    "        print ('X_train:',X_train.shape)\n",
    "        print ('Y_train:',Y_train.shape)\n",
    "        print ()\n",
    "        print ('X_val:',X_val.shape)\n",
    "        print ('Y_val:',Y_val.shape)\n",
    "\n",
    "        # Call backs to save weights\n",
    "        filepath= \"Experiments/weights_MODEL2_{}.hdf5\".format(seed)\n",
    "        checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy',verbose=1, save_best_only=True, mode='max')\n",
    "        #callbacks_list = [checkpoint]\n",
    "        \n",
    "        model2 = network2()\n",
    "        model2.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "        \n",
    "        model2.summary()\n",
    "        \n",
    "        start = time.time()\n",
    "\n",
    "        history2 = model2.fit(X_train, Y_train, validation_data=(X_val, Y_val), \n",
    "                  batch_size=32,\n",
    "                  epochs=7,\n",
    "                  verbose=2, \n",
    "                  callbacks=[checkpoint]) \n",
    "                  #class_weight={0:1.,1:1.}\n",
    "        end = time.time()\n",
    "        \n",
    "        model2.load_weights(\"Experiments/weights_MODEL2_{}.hdf5\".format(seed))\n",
    "        train_acc2 = accuracy_score(np.argmax(model2.predict(X_train),1),np.argmax(Y_train,1))\n",
    "        print(\"training accuracy = \",train_acc2)\n",
    "\n",
    "        val_acc2 = accuracy_score(np.argmax(model2.predict(X_val),1), np.argmax(Y_val,1))\n",
    "        print(\"validation accuracy = \",val_acc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 starting...\n",
      "experiment_id: 0\n",
      "X_train: (48270, 128, 188, 1)\n",
      "Y_train: (48270, 4)\n",
      "\n",
      "X_val: (15170, 128, 188, 1)\n",
      "Y_val: (15170, 4)\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 113, 173, 8)       2056      \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 113, 173, 8)       0         \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 28, 43, 8)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 13, 28, 8)         16392     \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 13, 28, 8)         0         \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 3, 7, 8)          0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 168)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 32)                5408      \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 4)                 132       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,988\n",
      "Trainable params: 23,988\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/7\n",
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.68774, saving model to Experiments\\weights_MODEL3_2022.hdf5\n",
      "3017/3017 - 1059s - loss: 0.6687 - accuracy: 0.7246 - val_loss: 1.0396 - val_accuracy: 0.6877 - 1059s/epoch - 351ms/step\n",
      "Epoch 2/7\n",
      "\n",
      "Epoch 2: val_accuracy did not improve from 0.68774\n",
      "3017/3017 - 783s - loss: 0.3679 - accuracy: 0.8454 - val_loss: 1.1873 - val_accuracy: 0.6623 - 783s/epoch - 259ms/step\n",
      "Epoch 3/7\n",
      "\n",
      "Epoch 3: val_accuracy improved from 0.68774 to 0.72327, saving model to Experiments\\weights_MODEL3_2022.hdf5\n",
      "3017/3017 - 780s - loss: 0.2765 - accuracy: 0.8776 - val_loss: 1.0764 - val_accuracy: 0.7233 - 780s/epoch - 259ms/step\n",
      "Epoch 4/7\n",
      "\n",
      "Epoch 4: val_accuracy improved from 0.72327 to 0.75465, saving model to Experiments\\weights_MODEL3_2022.hdf5\n",
      "3017/3017 - 773s - loss: 0.2329 - accuracy: 0.8951 - val_loss: 1.0605 - val_accuracy: 0.7546 - 773s/epoch - 256ms/step\n",
      "Epoch 5/7\n",
      "\n",
      "Epoch 5: val_accuracy improved from 0.75465 to 0.75735, saving model to Experiments\\weights_MODEL3_2022.hdf5\n",
      "3017/3017 - 1097s - loss: 0.2115 - accuracy: 0.9019 - val_loss: 1.2871 - val_accuracy: 0.7574 - 1097s/epoch - 364ms/step\n",
      "Epoch 6/7\n",
      "\n",
      "Epoch 6: val_accuracy did not improve from 0.75735\n",
      "3017/3017 - 1414s - loss: 0.1893 - accuracy: 0.9077 - val_loss: 1.6448 - val_accuracy: 0.7145 - 1414s/epoch - 469ms/step\n",
      "Epoch 7/7\n",
      "\n",
      "Epoch 7: val_accuracy did not improve from 0.75735\n",
      "3017/3017 - 1369s - loss: 0.1716 - accuracy: 0.9125 - val_loss: 1.9279 - val_accuracy: 0.7065 - 1369s/epoch - 454ms/step\n",
      "training accuracy =  0.9051584835301429\n",
      "validation accuracy =  0.7573500329597891\n"
     ]
    }
   ],
   "source": [
    "seed = 2022\n",
    "        \n",
    "for experiment_id in range(0,number_iterations):\n",
    "\n",
    "        print('Iteration {} starting...'.format(experiment_id))\n",
    "\n",
    "        print ('experiment_id: {}'.format(experiment_id))\n",
    "\n",
    "        \n",
    "        #X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.20, \n",
    "        #                                                    random_state=seed, shuffle = True)\n",
    "        #X_train, Y_train = shuffle(X_train,Y_train)\n",
    "        #X_val, Y_val = shuffle(X_val,Y_val)\n",
    "        \n",
    "        # Check shape\n",
    "        print ('X_train:',X_train.shape)\n",
    "        print ('Y_train:',Y_train.shape)\n",
    "        print ()\n",
    "        print ('X_val:',X_val.shape)\n",
    "        print ('Y_val:',Y_val.shape)\n",
    "\n",
    "        # Call backs to save weights\n",
    "        filepath= \"Experiments/weights_MODEL3_{}.hdf5\".format(seed)\n",
    "        checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy',verbose=1, save_best_only=True, mode='max')\n",
    "        #callbacks_list = [checkpoint]\n",
    "        \n",
    "        model3 = network3()\n",
    "        model3.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "        \n",
    "        model3.summary()\n",
    "        \n",
    "        start = time.time()\n",
    "\n",
    "        history3 = model3.fit(X_train, Y_train, validation_data=(X_val, Y_val), \n",
    "                  batch_size=16,\n",
    "                  epochs=7,\n",
    "                  verbose=2, \n",
    "                  callbacks=[checkpoint]) \n",
    "                  #class_weight={0:1.,1:1.}\n",
    "        end = time.time()\n",
    "        \n",
    "        model3.load_weights(\"Experiments/weights_MODEL3_{}.hdf5\".format(seed))\n",
    "        train_acc3 = accuracy_score(np.argmax(model3.predict(X_train),1),np.argmax(Y_train,1))\n",
    "        print(\"training accuracy = \",train_acc3)\n",
    "\n",
    "        val_acc3 = accuracy_score(np.argmax(model3.predict(X_val),1), np.argmax(Y_val,1))\n",
    "        print(\"validation accuracy = \",val_acc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 starting...\n",
      "experiment_id: 0\n",
      "X_train: (48270, 128, 188, 1)\n",
      "Y_train: (48270, 4)\n",
      "\n",
      "X_val: (15170, 128, 188, 1)\n",
      "Y_val: (15170, 4)\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 113, 173, 8)       2056      \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 113, 173, 8)       0         \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 28, 43, 8)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 13, 28, 8)         16392     \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 13, 28, 8)         0         \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 3, 7, 8)          0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 168)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 32)                5408      \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 4)                 132       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,988\n",
      "Trainable params: 23,988\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/7\n",
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.66203, saving model to Experiments\\weights_MODEL4_2022.hdf5\n",
      "1509/1509 - 1401s - loss: 0.6963 - accuracy: 0.7073 - val_loss: 0.9198 - val_accuracy: 0.6620 - 1401s/epoch - 928ms/step\n",
      "Epoch 2/7\n",
      "\n",
      "Epoch 2: val_accuracy improved from 0.66203 to 0.77179, saving model to Experiments\\weights_MODEL4_2022.hdf5\n",
      "1509/1509 - 721s - loss: 0.3482 - accuracy: 0.8470 - val_loss: 0.9227 - val_accuracy: 0.7718 - 721s/epoch - 478ms/step\n",
      "Epoch 3/7\n",
      "\n",
      "Epoch 3: val_accuracy did not improve from 0.77179\n",
      "1509/1509 - 712s - loss: 0.2497 - accuracy: 0.8831 - val_loss: 1.1257 - val_accuracy: 0.7375 - 712s/epoch - 472ms/step\n",
      "Epoch 4/7\n",
      "\n",
      "Epoch 4: val_accuracy did not improve from 0.77179\n",
      "1509/1509 - 703s - loss: 0.2161 - accuracy: 0.8951 - val_loss: 1.1000 - val_accuracy: 0.7619 - 703s/epoch - 466ms/step\n",
      "Epoch 5/7\n",
      "\n",
      "Epoch 5: val_accuracy did not improve from 0.77179\n",
      "1509/1509 - 701s - loss: 0.1879 - accuracy: 0.9045 - val_loss: 1.6407 - val_accuracy: 0.7612 - 701s/epoch - 465ms/step\n",
      "Epoch 6/7\n",
      "\n",
      "Epoch 6: val_accuracy did not improve from 0.77179\n",
      "1509/1509 - 703s - loss: 0.1772 - accuracy: 0.9088 - val_loss: 1.3421 - val_accuracy: 0.7361 - 703s/epoch - 466ms/step\n",
      "Epoch 7/7\n",
      "\n",
      "Epoch 7: val_accuracy did not improve from 0.77179\n",
      "1509/1509 - 702s - loss: 0.1641 - accuracy: 0.9120 - val_loss: 1.6863 - val_accuracy: 0.7392 - 702s/epoch - 465ms/step\n",
      "training accuracy =  0.8563704164077066\n",
      "validation accuracy =  0.7717864205669084\n"
     ]
    }
   ],
   "source": [
    "seed = 2022\n",
    "        \n",
    "for experiment_id in range(0,number_iterations):\n",
    "\n",
    "        print('Iteration {} starting...'.format(experiment_id))\n",
    "\n",
    "        print ('experiment_id: {}'.format(experiment_id))\n",
    "\n",
    "        \n",
    "        #X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.20, \n",
    "        #                                                    random_state=seed, shuffle = True)\n",
    "        #X_train, Y_train = shuffle(X_train,Y_train)\n",
    "        #X_val, Y_val = shuffle(X_val,Y_val)\n",
    "        \n",
    "        # Check shape\n",
    "        print ('X_train:',X_train.shape)\n",
    "        print ('Y_train:',Y_train.shape)\n",
    "        print ()\n",
    "        print ('X_val:',X_val.shape)\n",
    "        print ('Y_val:',Y_val.shape)\n",
    "\n",
    "        # Call backs to save weights\n",
    "        filepath= \"Experiments/weights_MODEL4_{}.hdf5\".format(seed)\n",
    "        checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy',verbose=1, save_best_only=True, mode='max')\n",
    "        #callbacks_list = [checkpoint]\n",
    "        \n",
    "        model4 = network4()\n",
    "        model4.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "        \n",
    "        model4.summary()\n",
    "        \n",
    "        start = time.time()\n",
    "\n",
    "        history4 = model4.fit(X_train, Y_train, validation_data=(X_val, Y_val), \n",
    "                  batch_size=32,\n",
    "                  epochs=7,\n",
    "                  verbose=2, \n",
    "                  callbacks=[checkpoint]) \n",
    "                  #class_weight={0:1.,1:1.}\n",
    "        end = time.time()\n",
    "        \n",
    "        model4.load_weights(\"Experiments/weights_MODEL4_{}.hdf5\".format(seed))\n",
    "        train_acc4 = accuracy_score(np.argmax(model4.predict(X_train),1),np.argmax(Y_train,1))\n",
    "        print(\"training accuracy = \",train_acc4)\n",
    "\n",
    "        val_acc4 = accuracy_score(np.argmax(model4.predict(X_val),1), np.argmax(Y_val,1))\n",
    "        print(\"validation accuracy = \",val_acc4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 starting...\n",
      "experiment_id: 0\n",
      "X_train: (48270, 128, 188, 1)\n",
      "Y_train: (48270, 4)\n",
      "\n",
      "X_val: (15170, 128, 188, 1)\n",
      "Y_val: (15170, 4)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 113, 173, 8)       2056      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 113, 173, 8)       0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 28, 43, 8)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 13, 28, 8)         16392     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 13, 28, 8)         0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 3, 7, 8)          0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 168)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                5408      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4)                 132       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,988\n",
      "Trainable params: 23,988\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/7\n",
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.74146, saving model to Experiments\\weights_model5_2022.hdf5\n",
      "3017/3017 - 1423s - loss: 0.5479 - accuracy: 0.7655 - val_loss: 1.8172 - val_accuracy: 0.7415 - 1423s/epoch - 472ms/step\n",
      "Epoch 2/7\n",
      "\n",
      "Epoch 2: val_accuracy improved from 0.74146 to 0.75643, saving model to Experiments\\weights_model5_2022.hdf5\n",
      "3017/3017 - 1414s - loss: 0.2558 - accuracy: 0.8826 - val_loss: 1.5482 - val_accuracy: 0.7564 - 1414s/epoch - 469ms/step\n",
      "Epoch 3/7\n",
      "\n",
      "Epoch 3: val_accuracy improved from 0.75643 to 0.75972, saving model to Experiments\\weights_model5_2022.hdf5\n",
      "3017/3017 - 1408s - loss: 0.1941 - accuracy: 0.9036 - val_loss: 1.5429 - val_accuracy: 0.7597 - 1408s/epoch - 467ms/step\n",
      "Epoch 4/7\n",
      "\n",
      "Epoch 4: val_accuracy did not improve from 0.75972\n",
      "3017/3017 - 1406s - loss: 0.1592 - accuracy: 0.9161 - val_loss: 2.6058 - val_accuracy: 0.7281 - 1406s/epoch - 466ms/step\n",
      "Epoch 5/7\n",
      "\n",
      "Epoch 5: val_accuracy improved from 0.75972 to 0.76829, saving model to Experiments\\weights_model5_2022.hdf5\n",
      "3017/3017 - 1406s - loss: 0.1541 - accuracy: 0.9179 - val_loss: 3.1390 - val_accuracy: 0.7683 - 1406s/epoch - 466ms/step\n",
      "Epoch 6/7\n",
      "\n",
      "Epoch 6: val_accuracy did not improve from 0.76829\n",
      "3017/3017 - 1402s - loss: 0.1410 - accuracy: 0.9220 - val_loss: 2.9548 - val_accuracy: 0.7457 - 1402s/epoch - 465ms/step\n",
      "Epoch 7/7\n",
      "\n",
      "Epoch 7: val_accuracy improved from 0.76829 to 0.78899, saving model to Experiments\\weights_model5_2022.hdf5\n",
      "3017/3017 - 1398s - loss: 0.1345 - accuracy: 0.9237 - val_loss: 3.3368 - val_accuracy: 0.7890 - 1398s/epoch - 463ms/step\n",
      "training accuracy =  0.9343277397969754\n",
      "validation accuracy =  0.7889914304548451\n"
     ]
    }
   ],
   "source": [
    "seed = 2022\n",
    "        \n",
    "for experiment_id in range(0,number_iterations):\n",
    "\n",
    "        print('Iteration {} starting...'.format(experiment_id))\n",
    "\n",
    "        print ('experiment_id: {}'.format(experiment_id))\n",
    "\n",
    "        \n",
    "        #X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.20, \n",
    "        #                                                    random_state=seed, shuffle = True)\n",
    "        #X_train, Y_train = shuffle(X_train,Y_train)\n",
    "        #X_val, Y_val = shuffle(X_val,Y_val)\n",
    "        \n",
    "        # Check shape\n",
    "        print ('X_train:',X_train.shape)\n",
    "        print ('Y_train:',Y_train.shape)\n",
    "        print ()\n",
    "        print ('X_val:',X_val.shape)\n",
    "        print ('Y_val:',Y_val.shape)\n",
    "\n",
    "        # Call backs to save weights\n",
    "        filepath= \"Experiments/weights_model5_{}.hdf5\".format(seed)\n",
    "        checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy',verbose=1, save_best_only=True, mode='max')\n",
    "        #callbacks_list = [checkpoint]\n",
    "        \n",
    "        model5 = network5()\n",
    "        model5.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "        \n",
    "        model5.summary()\n",
    "        \n",
    "        start = time.time()\n",
    "\n",
    "        history5 = model5.fit(X_train, Y_train, validation_data=(X_val, Y_val), \n",
    "                  batch_size=16,\n",
    "                  epochs=7,\n",
    "                  verbose=2, \n",
    "                  callbacks=[checkpoint]) \n",
    "                  #class_weight={0:1.,1:1.}\n",
    "        end = time.time()\n",
    "        \n",
    "        model5.load_weights(\"Experiments/weights_model5_{}.hdf5\".format(seed))\n",
    "        train_acc5 = accuracy_score(np.argmax(model5.predict(X_train),1),np.argmax(Y_train,1))\n",
    "        print(\"training accuracy = \",train_acc5)\n",
    "\n",
    "        val_acc5 = accuracy_score(np.argmax(model5.predict(X_val),1), np.argmax(Y_val,1))\n",
    "        print(\"validation accuracy = \",val_acc5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 starting...\n",
      "experiment_id: 0\n",
      "X_train: (48270, 128, 188, 1)\n",
      "Y_train: (48270, 4)\n",
      "\n",
      "X_val: (15170, 128, 188, 1)\n",
      "Y_val: (15170, 4)\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_10 (Conv2D)          (None, 113, 173, 8)       2056      \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 113, 173, 8)       0         \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPoolin  (None, 28, 43, 8)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 13, 28, 8)         16392     \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 13, 28, 8)         0         \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 3, 7, 8)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 168)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 32)                5408      \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 4)                 132       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,988\n",
      "Trainable params: 23,988\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/7\n",
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.60283, saving model to Experiments\\weights_2022.hdf5\n",
      "1509/1509 - 749s - loss: 0.7000 - accuracy: 0.7000 - val_loss: 1.5607 - val_accuracy: 0.6028 - 749s/epoch - 496ms/step\n",
      "Epoch 2/7\n",
      "\n",
      "Epoch 2: val_accuracy improved from 0.60283 to 0.64331, saving model to Experiments\\weights_2022.hdf5\n",
      "1509/1509 - 717s - loss: 0.4308 - accuracy: 0.8142 - val_loss: 1.8464 - val_accuracy: 0.6433 - 717s/epoch - 475ms/step\n",
      "Epoch 3/7\n",
      "\n",
      "Epoch 3: val_accuracy improved from 0.64331 to 0.65709, saving model to Experiments\\weights_2022.hdf5\n",
      "1509/1509 - 730s - loss: 0.3435 - accuracy: 0.8471 - val_loss: 2.4114 - val_accuracy: 0.6571 - 730s/epoch - 484ms/step\n",
      "Epoch 4/7\n",
      "\n",
      "Epoch 4: val_accuracy improved from 0.65709 to 0.68016, saving model to Experiments\\weights_2022.hdf5\n",
      "1509/1509 - 1337s - loss: 0.2883 - accuracy: 0.8667 - val_loss: 2.5349 - val_accuracy: 0.6802 - 1337s/epoch - 886ms/step\n",
      "Epoch 5/7\n",
      "\n",
      "Epoch 5: val_accuracy did not improve from 0.68016\n",
      "1509/1509 - 1345s - loss: 0.2558 - accuracy: 0.8799 - val_loss: 2.5970 - val_accuracy: 0.6724 - 1345s/epoch - 891ms/step\n",
      "Epoch 6/7\n",
      "\n",
      "Epoch 6: val_accuracy did not improve from 0.68016\n",
      "1509/1509 - 1346s - loss: 0.2250 - accuracy: 0.8904 - val_loss: 3.1217 - val_accuracy: 0.6660 - 1346s/epoch - 892ms/step\n",
      "Epoch 7/7\n",
      "\n",
      "Epoch 7: val_accuracy did not improve from 0.68016\n",
      "1509/1509 - 1345s - loss: 0.2078 - accuracy: 0.8944 - val_loss: 3.5563 - val_accuracy: 0.6526 - 1345s/epoch - 892ms/step\n",
      "training accuracy =  0.8832608245286928\n",
      "validation accuracy =  0.6801582069874753\n"
     ]
    }
   ],
   "source": [
    "seed = 2022\n",
    "        \n",
    "for experiment_id in range(0,number_iterations):\n",
    "\n",
    "        print('Iteration {} starting...'.format(experiment_id))\n",
    "\n",
    "        print ('experiment_id: {}'.format(experiment_id))\n",
    "\n",
    "        \n",
    "        #X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.20, \n",
    "        #                                                    random_state=seed, shuffle = True)\n",
    "        #X_train, Y_train = shuffle(X_train,Y_train)\n",
    "        #X_val, Y_val = shuffle(X_val,Y_val)\n",
    "        \n",
    "        # Check shape\n",
    "        print ('X_train:',X_train.shape)\n",
    "        print ('Y_train:',Y_train.shape)\n",
    "        print ()\n",
    "        print ('X_val:',X_val.shape)\n",
    "        print ('Y_val:',Y_val.shape)\n",
    "\n",
    "        # Call backs to save weights\n",
    "        filepath= \"Experiments/weights_MODEL6_{}.hdf5\".format(seed)\n",
    "        checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy',verbose=1, save_best_only=True, mode='max')\n",
    "        #callbacks_list = [checkpoint]\n",
    "        \n",
    "        model6 = network6()\n",
    "        model6.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "        \n",
    "        model6.summary()\n",
    "        \n",
    "        start = time.time()\n",
    "\n",
    "        history6 = model6.fit(X_train, Y_train, validation_data=(X_val, Y_val), \n",
    "                  batch_size=32,\n",
    "                  epochs=7,\n",
    "                  verbose=2, \n",
    "                  callbacks=[checkpoint]) \n",
    "                  #class_weight={0:1.,1:1.}\n",
    "        end = time.time()\n",
    "        \n",
    "        model6.load_weights(\"Experiments/weights_MODEL6_{}.hdf5\".format(seed))\n",
    "        train_acc6 = accuracy_score(np.argmax(model6.predict(X_train),1),np.argmax(Y_train,1))\n",
    "        print(\"training accuracy = \",train_acc6)\n",
    "\n",
    "        val_acc6 = accuracy_score(np.argmax(model6.predict(X_val),1), np.argmax(Y_val,1))\n",
    "        print(\"validation accuracy = \",val_acc6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 starting...\n",
      "experiment_id: 0\n",
      "X_train: (48270, 128, 188, 1)\n",
      "Y_train: (48270, 4)\n",
      "\n",
      "X_val: (15170, 128, 188, 1)\n",
      "Y_val: (15170, 4)\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_8 (Conv2D)           (None, 113, 173, 8)       2056      \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 113, 173, 8)       0         \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 28, 43, 8)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 13, 28, 8)         16392     \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 13, 28, 8)         0         \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 3, 7, 8)          0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 168)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 32)                5408      \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 4)                 132       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,988\n",
      "Trainable params: 23,988\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/7\n",
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.72044, saving model to Experiments\\weights_MODEL8_2022.hdf5\n",
      "755/755 - 1262s - loss: 0.7181 - accuracy: 0.6969 - val_loss: 1.3330 - val_accuracy: 0.7204 - 1262s/epoch - 2s/step\n",
      "Epoch 2/7\n",
      "\n",
      "Epoch 2: val_accuracy improved from 0.72044 to 0.73757, saving model to Experiments\\weights_MODEL8_2022.hdf5\n",
      "755/755 - 1033s - loss: 0.4014 - accuracy: 0.8235 - val_loss: 1.8750 - val_accuracy: 0.7376 - 1033s/epoch - 1s/step\n",
      "Epoch 3/7\n",
      "\n",
      "Epoch 3: val_accuracy did not improve from 0.73757\n",
      "755/755 - 1291s - loss: 0.3096 - accuracy: 0.8586 - val_loss: 2.5543 - val_accuracy: 0.7196 - 1291s/epoch - 2s/step\n",
      "Epoch 4/7\n",
      "\n",
      "Epoch 4: val_accuracy did not improve from 0.73757\n",
      "755/755 - 694s - loss: 0.2511 - accuracy: 0.8811 - val_loss: 2.5998 - val_accuracy: 0.7254 - 694s/epoch - 919ms/step\n",
      "Epoch 5/7\n",
      "\n",
      "Epoch 5: val_accuracy improved from 0.73757 to 0.74944, saving model to Experiments\\weights_MODEL8_2022.hdf5\n",
      "755/755 - 712s - loss: 0.2173 - accuracy: 0.8931 - val_loss: 3.0623 - val_accuracy: 0.7494 - 712s/epoch - 943ms/step\n",
      "Epoch 6/7\n",
      "\n",
      "Epoch 6: val_accuracy improved from 0.74944 to 0.77179, saving model to Experiments\\weights_MODEL8_2022.hdf5\n",
      "755/755 - 712s - loss: 0.2017 - accuracy: 0.8992 - val_loss: 3.7261 - val_accuracy: 0.7718 - 712s/epoch - 943ms/step\n",
      "Epoch 7/7\n",
      "\n",
      "Epoch 7: val_accuracy did not improve from 0.77179\n",
      "755/755 - 712s - loss: 0.2009 - accuracy: 0.8991 - val_loss: 3.9039 - val_accuracy: 0.7533 - 712s/epoch - 943ms/step\n",
      "training accuracy =  0.9188937228091982\n",
      "validation accuracy =  0.7717864205669084\n"
     ]
    }
   ],
   "source": [
    "seed = 2022\n",
    "        \n",
    "for experiment_id in range(0,number_iterations):\n",
    "\n",
    "        print('Iteration {} starting...'.format(experiment_id))\n",
    "\n",
    "        print ('experiment_id: {}'.format(experiment_id))\n",
    "\n",
    "        \n",
    "        #X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.20, \n",
    "        #                                                    random_state=seed, shuffle = True)\n",
    "        #X_train, Y_train = shuffle(X_train,Y_train)\n",
    "        #X_val, Y_val = shuffle(X_val,Y_val)\n",
    "        \n",
    "        # Check shape\n",
    "        print ('X_train:',X_train.shape)\n",
    "        print ('Y_train:',Y_train.shape)\n",
    "        print ()\n",
    "        print ('X_val:',X_val.shape)\n",
    "        print ('Y_val:',Y_val.shape)\n",
    "\n",
    "        # Call backs to save weights\n",
    "        filepath= \"Experiments/weights_MODEL8_{}.hdf5\".format(seed)\n",
    "        checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy',verbose=1, save_best_only=True, mode='max')\n",
    "        #callbacks_list = [checkpoint]\n",
    "        \n",
    "        model8 = network1()\n",
    "        model8.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "        \n",
    "        model8.summary()\n",
    "        \n",
    "        start = time.time()\n",
    "\n",
    "        history8 = model8.fit(X_train, Y_train, validation_data=(X_val, Y_val), \n",
    "                  batch_size=64,\n",
    "                  epochs=7,\n",
    "                  verbose=2, \n",
    "                  callbacks=[checkpoint]) \n",
    "                  #class_weight={0:1.,1:1.}\n",
    "        end = time.time()\n",
    "        \n",
    "        model8.load_weights(\"Experiments/weights_MODEL8_{}.hdf5\".format(seed))\n",
    "        train_acc8 = accuracy_score(np.argmax(model8.predict(X_train),1),np.argmax(Y_train,1))\n",
    "        print(\"training accuracy = \",train_acc8)\n",
    "\n",
    "        val_acc8 = accuracy_score(np.argmax(model8.predict(X_val),1), np.argmax(Y_val,1))\n",
    "        print(\"validation accuracy = \",val_acc8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 starting...\n",
      "experiment_id: 0\n",
      "X_train: (48270, 128, 188, 1)\n",
      "Y_train: (48270, 4)\n",
      "\n",
      "X_val: (15170, 128, 188, 1)\n",
      "Y_val: (15170, 4)\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_10 (Conv2D)          (None, 113, 173, 8)       2056      \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 113, 173, 8)       0         \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPoolin  (None, 28, 43, 8)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 13, 28, 8)         16392     \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 13, 28, 8)         0         \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 3, 7, 8)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 168)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 32)                5408      \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 4)                 132       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,988\n",
      "Trainable params: 23,988\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/7\n",
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.62749, saving model to Experiments\\weights_MODEL9_2022.hdf5\n",
      "755/755 - 1423s - loss: 0.7780 - accuracy: 0.6749 - val_loss: 1.0224 - val_accuracy: 0.6275 - 1423s/epoch - 2s/step\n",
      "Epoch 2/7\n",
      "\n",
      "Epoch 2: val_accuracy improved from 0.62749 to 0.70138, saving model to Experiments\\weights_MODEL9_2022.hdf5\n",
      "755/755 - 735s - loss: 0.4279 - accuracy: 0.8139 - val_loss: 0.9114 - val_accuracy: 0.7014 - 735s/epoch - 973ms/step\n",
      "Epoch 3/7\n",
      "\n",
      "Epoch 3: val_accuracy improved from 0.70138 to 0.73085, saving model to Experiments\\weights_MODEL9_2022.hdf5\n",
      "755/755 - 1345s - loss: 0.2927 - accuracy: 0.8697 - val_loss: 0.9216 - val_accuracy: 0.7309 - 1345s/epoch - 2s/step\n",
      "Epoch 4/7\n",
      "\n",
      "Epoch 4: val_accuracy improved from 0.73085 to 0.74127, saving model to Experiments\\weights_MODEL9_2022.hdf5\n",
      "755/755 - 1340s - loss: 0.2420 - accuracy: 0.8870 - val_loss: 0.9230 - val_accuracy: 0.7413 - 1340s/epoch - 2s/step\n",
      "Epoch 5/7\n",
      "\n",
      "Epoch 5: val_accuracy improved from 0.74127 to 0.74924, saving model to Experiments\\weights_MODEL9_2022.hdf5\n",
      "755/755 - 1339s - loss: 0.2131 - accuracy: 0.8981 - val_loss: 1.0494 - val_accuracy: 0.7492 - 1339s/epoch - 2s/step\n",
      "Epoch 6/7\n",
      "\n",
      "Epoch 6: val_accuracy improved from 0.74924 to 0.75129, saving model to Experiments\\weights_MODEL9_2022.hdf5\n",
      "755/755 - 1339s - loss: 0.1961 - accuracy: 0.9041 - val_loss: 0.9468 - val_accuracy: 0.7513 - 1339s/epoch - 2s/step\n",
      "Epoch 7/7\n",
      "\n",
      "Epoch 7: val_accuracy improved from 0.75129 to 0.75300, saving model to Experiments\\weights_MODEL9_2022.hdf5\n",
      "755/755 - 1336s - loss: 0.1756 - accuracy: 0.9096 - val_loss: 1.0718 - val_accuracy: 0.7530 - 1336s/epoch - 2s/step\n",
      "training accuracy =  0.9241143567433189\n",
      "validation accuracy =  0.7529993408042188\n"
     ]
    }
   ],
   "source": [
    "seed = 2022\n",
    "        \n",
    "for experiment_id in range(0,number_iterations):\n",
    "\n",
    "        print('Iteration {} starting...'.format(experiment_id))\n",
    "\n",
    "        print ('experiment_id: {}'.format(experiment_id))\n",
    "\n",
    "        \n",
    "        #X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.20, \n",
    "        #                                                    random_state=seed, shuffle = True)\n",
    "        #X_train, Y_train = shuffle(X_train,Y_train)\n",
    "        #X_val, Y_val = shuffle(X_val,Y_val)\n",
    "        \n",
    "        # Check shape\n",
    "        print ('X_train:',X_train.shape)\n",
    "        print ('Y_train:',Y_train.shape)\n",
    "        print ()\n",
    "        print ('X_val:',X_val.shape)\n",
    "        print ('Y_val:',Y_val.shape)\n",
    "\n",
    "        # Call backs to save weights\n",
    "        filepath= \"Experiments/weights_MODEL9_{}.hdf5\".format(seed)\n",
    "        checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy',verbose=1, save_best_only=True, mode='max')\n",
    "        #callbacks_list = [checkpoint]\n",
    "        \n",
    "        model9 = network4()\n",
    "        model9.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "        \n",
    "        model9.summary()\n",
    "        \n",
    "        start = time.time()\n",
    "\n",
    "        history9 = model9.fit(X_train, Y_train, validation_data=(X_val, Y_val), \n",
    "                  batch_size=64,\n",
    "                  epochs=7,\n",
    "                  verbose=2, \n",
    "                  callbacks=[checkpoint]) \n",
    "                  #class_weight={0:1.,1:1.}\n",
    "        end = time.time()\n",
    "        \n",
    "        model9.load_weights(\"Experiments/weights_MODEL9_{}.hdf5\".format(seed))\n",
    "        train_acc9 = accuracy_score(np.argmax(model9.predict(X_train),1),np.argmax(Y_train,1))\n",
    "        print(\"training accuracy = \",train_acc9)\n",
    "\n",
    "        val_acc9 = accuracy_score(np.argmax(model9.predict(X_val),1), np.argmax(Y_val,1))\n",
    "        print(\"validation accuracy = \",val_acc9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 0:\n",
      "training accuracy = \n",
      "validation accuracy = \n",
      "model 1:\n",
      "training accuracy =  0.9192044748290864\n",
      "validation accuracy =  0.6940013183915623\n",
      "model 2:\n",
      "training accuracy =  0.9241765071472965\n",
      "validation accuracy =  0.7569545154911008\n",
      "model 3:\n",
      "training accuracy =  0.9099440646364202\n",
      "validation accuracy =  0.7462096242584048\n",
      "model 4:\n",
      "training accuracy =  0.8646985705407085\n",
      "validation accuracy =  0.7301911667765326\n",
      "model 5:\n",
      "training accuracy =  0.906297907603066\n",
      "validation accuracy =  0.7625576796308504\n",
      "model 6:\n",
      "training accuracy =  0.8832608245286928\n",
      "validation accuracy =  0.6801582069874753\n",
      "model 8:\n",
      "training accuracy =  0.9302258131344521\n",
      "validation accuracy =  0.7647330257086354\n",
      "model 9:\n",
      "training accuracy =  0.894178578827429\n",
      "validation accuracy =  0.7266315095583388\n"
     ]
    }
   ],
   "source": [
    "print(\"model 0:\")\n",
    "print(\"training accuracy = \",)\n",
    "print(\"validation accuracy = \",)\n",
    "print(\"model 1:\")\n",
    "print(\"training accuracy = \",train_acc1)\n",
    "print(\"validation accuracy = \",val_acc1)\n",
    "print(\"model 2:\")\n",
    "print(\"training accuracy = \",train_acc2)\n",
    "print(\"validation accuracy = \",val_acc2)\n",
    "print(\"model 3:\")\n",
    "print(\"training accuracy = \",train_acc3)\n",
    "print(\"validation accuracy = \",val_acc3)\n",
    "print(\"model 4:\")\n",
    "print(\"training accuracy = \",train_acc4)\n",
    "print(\"validation accuracy = \",val_acc4)\n",
    "print(\"model 5:\")\n",
    "print(\"training accuracy = \",train_acc5)\n",
    "print(\"validation accuracy = \",val_acc5)\n",
    "print(\"model 6:\")\n",
    "print(\"training accuracy = \",train_acc6)\n",
    "print(\"validation accuracy = \",val_acc6)\n",
    "print(\"model 8:\")\n",
    "print(\"training accuracy = \",train_acc8)\n",
    "print(\"validation accuracy = \",val_acc8)\n",
    "print(\"model 9:\")\n",
    "print(\"training accuracy = \",train_acc9)\n",
    "print(\"validation accuracy = \",val_acc9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history5.history['accuracy'])\n",
    "plt.plot(history5.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "        \n",
    "plt.plot(history5.history['loss'])\n",
    "plt.plot(history5.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7097   94  189  160]\n",
      " [ 618  850  216 1096]\n",
      " [  50   20 1629  671]\n",
      " [ 331   32  210 1907]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.877     0.941     0.908      7540\n",
      "           1      0.853     0.306     0.450      2780\n",
      "           2      0.726     0.687     0.706      2370\n",
      "           3      0.497     0.769     0.604      2480\n",
      "\n",
      "    accuracy                          0.757     15170\n",
      "   macro avg      0.738     0.676     0.667     15170\n",
      "weighted avg      0.787     0.757     0.743     15170\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(metrics.confusion_matrix(np.argmax(Y_val,1), np.argmax(model2.predict(X_val),1)))\n",
    "\n",
    "# Print the precision and recall, among other metrics\n",
    "print(metrics.classification_report(np.argmax(Y_val,1), np.argmax(model2.predict(X_val),1), digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7214   16   95  215]\n",
      " [ 690  858  327  905]\n",
      " [  50   65 1288  967]\n",
      " [ 421   25   74 1960]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.861     0.957     0.907      7540\n",
      "           1      0.890     0.309     0.458      2780\n",
      "           2      0.722     0.543     0.620      2370\n",
      "           3      0.484     0.790     0.601      2480\n",
      "\n",
      "    accuracy                          0.746     15170\n",
      "   macro avg      0.739     0.650     0.646     15170\n",
      "weighted avg      0.783     0.746     0.730     15170\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(metrics.confusion_matrix(np.argmax(Y_val,1), np.argmax(model3.predict(X_val),1)))\n",
    "\n",
    "# Print the precision and recall, among other metrics\n",
    "print(metrics.classification_report(np.argmax(Y_val,1), np.argmax(model3.predict(X_val),1), digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7258    4   79  199]\n",
      " [ 890 1062  390  438]\n",
      " [  76   70  708 1516]\n",
      " [ 319   10  102 2049]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.850     0.963     0.903      7540\n",
      "           1      0.927     0.382     0.541      2780\n",
      "           2      0.554     0.299     0.388      2370\n",
      "           3      0.488     0.826     0.613      2480\n",
      "\n",
      "    accuracy                          0.730     15170\n",
      "   macro avg      0.704     0.617     0.611     15170\n",
      "weighted avg      0.758     0.730     0.709     15170\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(metrics.confusion_matrix(np.argmax(Y_val,1), np.argmax(model4.predict(X_val),1)))\n",
    "\n",
    "# Print the precision and recall, among other metrics\n",
    "print(metrics.classification_report(np.argmax(Y_val,1), np.argmax(model4.predict(X_val),1), digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7076  223  174   67]\n",
      " [ 665  724  322 1069]\n",
      " [  53   14 2112  191]\n",
      " [ 242    7  174 2057]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.881     0.938     0.909      7540\n",
      "           1      0.748     0.260     0.386      2780\n",
      "           2      0.759     0.891     0.820      2370\n",
      "           3      0.608     0.829     0.702      2480\n",
      "\n",
      "    accuracy                          0.789     15170\n",
      "   macro avg      0.749     0.730     0.704     15170\n",
      "weighted avg      0.793     0.789     0.765     15170\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(metrics.confusion_matrix(np.argmax(Y_val,1), np.argmax(model5.predict(X_val),1)))\n",
    "\n",
    "# Print the precision and recall, among other metrics\n",
    "print(metrics.classification_report(np.argmax(Y_val,1), np.argmax(model5.predict(X_val),1), digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7069   74  247  150]\n",
      " [ 461  720  277 1322]\n",
      " [  50   10 1889  421]\n",
      " [ 308   30  219 1923]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.896     0.938     0.916      7540\n",
      "           1      0.863     0.259     0.398      2780\n",
      "           2      0.718     0.797     0.755      2370\n",
      "           3      0.504     0.775     0.611      2480\n",
      "\n",
      "    accuracy                          0.765     15170\n",
      "   macro avg      0.745     0.692     0.670     15170\n",
      "weighted avg      0.798     0.765     0.746     15170\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(metrics.confusion_matrix(np.argmax(Y_val,1), np.argmax(model8.predict(X_val),1)))\n",
    "\n",
    "# Print the precision and recall, among other metrics\n",
    "print(metrics.classification_report(np.argmax(Y_val,1), np.argmax(model8.predict(X_val),1), digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7186   14  179  161]\n",
      " [ 662  808  222 1088]\n",
      " [  60  260  836 1214]\n",
      " [ 212    0   75 2193]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.885     0.953     0.918      7540\n",
      "           1      0.747     0.291     0.418      2780\n",
      "           2      0.637     0.353     0.454      2370\n",
      "           3      0.471     0.884     0.615      2480\n",
      "\n",
      "    accuracy                          0.727     15170\n",
      "   macro avg      0.685     0.620     0.601     15170\n",
      "weighted avg      0.753     0.727     0.704     15170\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(metrics.confusion_matrix(np.argmax(Y_val,1), np.argmax(model9.predict(X_val),1)))\n",
    "\n",
    "# Print the precision and recall, among other metrics\n",
    "print(metrics.classification_report(np.argmax(Y_val,1), np.argmax(model9.predict(X_val),1), digits=3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu2",
   "language": "python",
   "name": "gpu2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
